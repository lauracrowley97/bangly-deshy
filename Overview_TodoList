Advanced Discrete Simulation
Assignment 1
Group 14
20 February 2019

**Overview of Data Cleaning Files:
Road_cleaning_FINAL.py - script that cleans the road data
BurningMoreBridges.R - script that cleans the bride data, based on the cleaned road data

**Road Cleaning
First, we clean the road data from .lrps.htm files (original from the ministry) with a python script. Inside the script, the following functions are defined and called:
    1. The input files are "RoadName".lrps.htm files and a list of all the road names.
    2. import_data() this function reads in the road files ("name".lrps.htm) based on a list of names of all the roads in Bangladesh. It then iterates through all the road files, opening and closing each one in turn, while reading in the data to data frames and performing some first-pass data cleaning (removing columns of NAs, renaming column headers, etc.). It then calls determine_outliers on the data, and afterwards saves the cleaned data to a tab separated file, with columns that contain data about LRP Number, Road Change, LRP Type, Description, Latitude, Longitude, and Road.
    3. determine_outliers() calculates (for the longitude and latitude separately and simultaneously) the difference between a longitude or latitude entry, and the corresponding value in the entry above and below it. It then takes the standard deviation of these difference values and uses that to create a cutoff value. When a difference is above a cutoff value, the function find_replace_outliers() is called, otherwise the data is appended to a data frame that stores the cleaned data.
    4. find_replace_outliers() collects the outliers in the road data (identified in determine_outliers) into a data frame of outliers. It then identifies outliers that are unreasonably far away from both the entry above it and the entry below it (i.e. isolating the outlier (in the case of a single outlier) from the points above and below it that are not outliers themselves). These outliers are replaced by an interpolation (simple mean) of the entries above and below the outlier entry. The interpolated points are then merged with the data frame and used to replace the outlier points they correspond to.
    5. The output after calling these three function is cleaned_all_road_data.csv

**Bridge Cleaning
Second, we clean the bridge data from the BMMS_overview.csv
    1. The input files are the .csv output from the road cleaning, the BMMS_overview.csv, and a list of all the road names.
    2. Then the script iterates through each bridge point and compares it to the lrp in the road data to see if anything related to it has changed.
    3. If so, the corresponding bridge point needs regenerating.
    4. There are 4 ways of converting bridge point location from the road data.
	a. If the LRP number from the road data and the bridge data match, but their latitude and longitude coordinates do not, the latitude and longitude coordinates for the bridge data are replaced by the latitude and longitude coordinates from the matching (cleaned) road data.
	b. If the short line distance between a bridge longitude and latitude and a road point longitude and latitude is less than a threshold of 20 meters, then the latitude and longitude coordinates for the bridge data are replaced by the latitude and longitude coordinates from the road data with the closest coordinate match.
	c. If the chainage difference (difference between road and bridge chainage) is less than the threshold of 10 meters, than the latitude and longitude coordinates for the bridge data are replaced by the latitude and longitude coordinates from the road data with the closest chainage match.
	d. If the chainage difference (##update description of this) is less than the threshold of 200 meters, (##update description of this)
    5. If nothing else matched closely enough from the four previous methods, then the bridge location data is replaced by an interpolation (simple mean) of the entries above and below the outlier entry.
    6. The output files are a version of the BMMS_overview with corrected data (BMMS_Overview_Cleaned.csv) and a change log (change_log.csv)

**Preparation for Java (Save as TCV)
Third, another R script (Sava_as_TCV.R) generates the .tcv of the roads, that is required for simulation
    1. The BMMS_Overview.csv (##update description of this / ##needs to be updated to BMMS_Overview_Cleaned.csv in R file?) is adapted to the required format form the .csv file generated during the data cleaning.
    2. The description of the TCV file from brightspace (below) is used to reformat the cleaned bridge data in the proper format for import. 
          "infrastructure/_roads.tcv: a tab-separated text-file with processed information from the RMMS dataset. It contains a first line with explanation, and the following tab-separated data starting from line 2, with one road per line.
              o road name: the official name of the road
              o lrp1: the name of the first LRP of the road
              o lat1: the latitude of lrp1
              o lon1: the longitude of lrp1
              o ...
              o lrpn: the name of the last LRP of the road
              o latn: the latitude of lrpn
              o lonn: the longitude of lrpn"
    3. The output is saved as data.tcv

**Types of Inaccuracy
##Notes from class -- to do this afternoon
Maybe make a summary table like this:
  what we cleaned			what type of data issue it was (syntactic, semantic, pragmatic etc etc)			how we cleaned it

  
Dealing with semantic inaccuracy in Chainage 
 There are 29 bridges whose Lat/Lon are estimated with 'road_interpolate' and are longer than 50m and on an N road.
 There 2 bridges whose Lat/Lon are estimated with 'road_chainage' and are longer than 50m and on an N road. 
 For a number of reasons, we have decided that the error checking of these bridges should be completed manually 
 i.e. look up the bridge name on google maps and check the latitude and longitude co-ordinates.
 Justification:
    1. Difficulty in fixing: there are reasonably quick ways of automating the estimate of the chainage of LRP point in a road (some % of the straight-line distance between points).
    But there is no reliable way of checking that the chainage of the bridge points are correct other than manually. 
    2. Errors have low impact on pragmatic precision because these bridges are still on the correct road. 
    The fact that they may be a certain number of kilometers (max the difference in chainage changes due to maintenance/straightening is order of magnitude tens of km)
    will not affect the analysis. We assume that the assessment of the importance of a bridge is mostly due to the areas it links, and the road it is on, which is preserved.
    
Error searching revealed the following errors/changes:



Semantic incompleteness error in the bridge data:
There are entire roads in the RMMS zip (##update exact number here please) for which no corresponding files of bridges exist in the BMMS zip.
This means that for entire roads, no bridges are included. 
We have included this list in our output files but have not fixed this due to time constraints but would like the client to be made aware of this incompleteness.






