Advanced Discrete Simulation
Assignment 1
Group 14
20 February 2019

Overview of Data Cleaning Files:
Road_cleaning_FINAL.py - script that cleans the road data
BurningMoreBridges.R - script that cleans the bride data, based on the cleaned road data

Road Cleaning
First we clean the road data from .lrps.htm files (original from the ministry) with a python script. Inside the script, the following cleaning process takes place:
    1. The functions that will clean the data are defined and run.
	a. import_data() this function reads in the road files ("name".lrps.htm) based on a list of names of all the roads in Bangladesh. It then iterates through all the road files, opening and closing each one in turn, while reading in the data to data frames and performing some first-pass data cleaning (removing columns of NAs, renaming column headers, etc.). It then calls determine_outliers on the data, and afterwards saves the cleaned data to a tab separated file.
	b. determine_outliers() calculates (for the longitude and latitude separately and simultaneously) the difference between a longitude or latitude entry, and the corresponding value in the entry above and below it. It then takes the standard deviation of these difference values and uses that to create a cutoff value. When a difference is above a cutoff value, the function find_replace_outliers() is called, otherwise the data is appended to a data frame that stores the cleaned data.
	c. find_replace_outliers() collects the outliers in the road data (identified in determine_outliers) into a data frame of outliers. It then identifies outliers that are unreasonably far away from both the entry above it and the entry below it (i.e. isolating the outlier (in the case of a single outlier) from the points above and below it that are not outliers themselves). These outliers are replaced by an interpolation (simple mean) of the entries above and below the outlier entry. The interpolated points are then merged with the data frame and used to replace the outlier points they correspond to.
	c. 
 htm need to be imported with pandas: takes a list of the roadnames to iterate through every .lrps file and convert
    2. Takes one road at a time and looks for outliers of lrp points.
    3. Outliers that are of type 'bridge' are interpolated.
    4. all other outliers are (TO BE DECIDED...if no time we just delete these)
    5. Chainage (see below, not dealt with here)
    6. output files: file of all changed/deleted lrp points.
          ...also output a csv for each road with column names (road name,lrp number, lat, lon, chainage, updated (y/n))...containing all lrp points and whethere they were changed

An initial visual scan of the generated co-ordinates should be completed at this point.

Next script is an R script to clean the bridge data
    1. Uses the .csv output from the roads, and the BMMS_overview.csv initially.
    2. Iterates through each bridge point and compares it to the lrp in the road data to see if anything related to it has changed
    3. If so, the corresponding bridge point needs regenerating
    4. There are 4 ways of converting bridge point location from the road data
    5. output files: file of all changed/deleted bridge lrp points
              ...... also a the output csv of the BMMS_overview with corrected data
    


Another R script generats the .tcv of the roads, that is required for simulation
    1. this is adapted to the required format form the .csv file generated in the first python
    2. Pretty straight forward - see brightspace: 
          "infrastructure/_roads.tcv: a tab-separated text-file with processed information from the
          RMMS dataset. It contains a first line with explanation, and the following tab-separated data
          starting from line 2, with one road per line. 

              o road name: the official name of the road
              o lrp1: the name of the first LRP of the road
              o lat1: the latitude of lrp1
              o lon1: the longitude of lrp1
              o ...
              o lrpn: the name of the last LRP of the road
              o latn: the latitude of lrpn
              o lonn: the longitude of lrpn"
              
              
 Dealing with semantic inaccuracy in Chainage
 
 There are 29 bridges whose Lat/Lon are estimated with 'road_interpolate' and are longer than 50m and on an N road.
 There 2 bridges whose Lat/Lon are estimated with 'road_chainage' and are longer than 50m and on an N road. 
 For a number of reasons, we have decided that the error checking of these bridges should be completed manually 
 i.e. look up the bridge name on google maps and check the lat/lon co-ordinates.
 Justification:
    1. Difficulty in fixing: there are reasonably quick ways of automating the estimate of the chainage of LRP point in a road (some % of the straight-line distance between points).
    But there is no reliable way of checking that the chainage of the bridge points are correct other than manually. 
    2. Errors have low impact on pragmatic precision because these bridges are still on the correct road. 
    The fact that they may be a certain number of kilometers (max the difference in chainage changes due to maintenance/straightening is order of magnitude tens of km).
    will not effect the analysis. We assume that the assessment of the importance of a bridge is mostly due to the areas it links, and the road it is on, which is preserved.
    
Error searching revealed the following errors/changes:






Semantic incompleteness error in the bridge data:
There are entire roads in the RMMS zip ( exact number here please) for which no corresponding files of bridges exist in the BMMS zip.
This means that for entire roads, no bridges are included. 
We have included this list in our output files but have not fixed this due to time constraints but would like the client to be made aware of this incompleteness.
