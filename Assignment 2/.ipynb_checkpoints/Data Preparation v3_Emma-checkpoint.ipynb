{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation File\n",
    "## Group 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data files\n",
    "# load in road file\n",
    "roads = pd.read_csv('_roads3.csv')\n",
    "# load in bridge file\n",
    "bridges = pd.read_excel('BMMS_overview.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all roadnames\n",
    "# from road file\n",
    "road_list = list(roads.road.unique())\n",
    "road_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on the N1 first\n",
    "def prep_road():\n",
    "    #road data\n",
    "    data_fr = roads[roads['road'] == roadname]\n",
    "    data_fr = data_fr[['road','lrp','lat','lon','chainage']] # subset desired columns\n",
    "    data_fr.columns = ['Road','LRPName','Lat','Lon','Chainage']\n",
    "    return data_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_bridge():\n",
    "    #bridge data\n",
    "    data_fb = bridges[bridges['road'] == roadname]\n",
    "    data_fb = data_fb.dropna(subset =['width']) # drop duplicates\n",
    "    data_fb = data_fb[['road','LRPName','name','chainage','length','condition','lat','lon']] # subset desired columns\n",
    "    data_fb.columns = ['Road','LRPName','Description','Chainage','Length','Cat','Lat','Lon']\n",
    "    data_fb = data_fb.sort_values(by = ['Chainage','LRPName'])\n",
    "    data_fb = data_fb.reset_index(drop = True)\n",
    "    return data_fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean duplicate L/R briges before merge\n",
    "#where LRPName is the same, compare Cat and drop the lower one (if Cat same, drop second one)\n",
    "def clean_lr(data_fb):\n",
    "    for i in range(len(data_fb)):\n",
    "        if i < len(data_fb)-1:\n",
    "            if data_fb.LRPName.iloc[i,] == data_fb.LRPName.iloc[i+1,]:\n",
    "                #print(\"same LRP\")\n",
    "                if data_fb.Cat.iloc[i,] == data_fb.Cat.iloc[i+1,]:\n",
    "    #                 print(\"same Cat dropped second entry by default\")\n",
    "                    data_fb.drop(data_fb.index[i+1], inplace = True)\n",
    "                elif data_fb.Cat.iloc[i,] < data_fb.Cat.iloc[i+1,]:\n",
    "    #                 print(\"first Cat greater dropped second entry\")\n",
    "                    #testy.drop(testy.index[[1,3]])\n",
    "                    data_fb.drop(data_fb.index[i+1], inplace = True)\n",
    "                elif data_fb.Cat.iloc[i,] > data_fb.Cat.iloc[i+1,]:\n",
    "    #                 print(\"second Cat greater dropped first entry\")\n",
    "                    data_fb.drop(data_fb.index[i], inplace = True)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    return data_fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# append files\n",
    "def join_roadbridge(data_fr,data_fb):\n",
    "    data = data_fr.append(data_fb, ignore_index = True, sort = False)\n",
    "    data = data.sort_values(by = ['LRPName']) \n",
    "    data = data.reset_index(drop = True)\n",
    "    return data\n",
    "    # later, add here instead of calling \"n1\" everywhere, use a variable (or loop) to apply this to all roads\n",
    "    # N1.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "#where LRPName repeated from road/brige file, drop road LRP.\n",
    "def bridge_priority(data):  \n",
    "    for i in range(len(data)):\n",
    "        if i < len(data)-1:\n",
    "            if data.LRPName.iloc[i,] == data.LRPName.iloc[i+1,]:\n",
    "                #print(\"same LRP\")\n",
    "                if data.Description.iloc[i,] == \"\":\n",
    "    #                 print(\"des null, is road point, drop it\")\n",
    "                    data.drop(data.index[i], inplace = True)\n",
    "                elif data.Description.iloc[i,] != \"\":\n",
    "    #                 print(\"des exists, is bridge point, drop other one\")\n",
    "                    data.drop(data.index[i+1], inplace = True)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up columns for simio\n",
    "def simio_columns(data):\n",
    "    # Set up Node Name column\n",
    "    data = data.sort_values(by = ['Chainage'])\n",
    "    data = data.reset_index(drop = True)\n",
    "    data[\"Next Node\"] = data.LRPName.shift(-1)\n",
    "    data.loc[data.LRPName.str.contains(\"LRPE\", case = False), \"Next Node\"] = \"PreRome\"\n",
    "    \n",
    "    # Set up Add On Process column\n",
    "    data.loc[data.Length.notnull(), \"Add On Process\"] = \"BridgesDelay\"\n",
    "    data.loc[data.Length.isnull(), \"Add On Process\"] = \"BlankProcess\"\n",
    "    # N1.head(10)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "def save_for_simio(data):\n",
    "    data.to_csv(\"data_clean.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this into loop?\n",
    "for roadname in road_list: #need file in directory\n",
    "    prep_road()\n",
    "    prep_bridge()\n",
    "    clean_lr(data_fb)\n",
    "    join_roadbridge(data_fr,data_fb)\n",
    "    bridge_priority(data)\n",
    "    simio_columns(data)\n",
    "    save_for_simio(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
